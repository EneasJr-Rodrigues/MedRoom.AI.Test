{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee17e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddf659",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d655928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import word2vec\n",
    "import multiprocessing\n",
    "import sklearn\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f63f6",
   "metadata": {},
   "source": [
    "### Functions to Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.pop(stop_words.index('não'))\n",
    "new_stopwords = ('bom', 'dia', 'ola', 'eu')\n",
    "for i in new_stopwords:\n",
    "    stop_words.append(i)\n",
    "    \n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def anonymizer(text,stop_words):\n",
    "    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    text = re.sub(' +', ' ', str(text).lower())\n",
    "    text = re.sub('((http?|ftp|smtp):\\/\\/)?(www.)?[a-z0-9]+\\.[a-z]+(\\/[a-zA-Z0-9#]+\\/?)*', ' ', str(text).lower())\n",
    "    text = re.sub('\\S+@\\S+', ' ', str(text).lower())\n",
    "    text = re.sub('@\\S+', ' ', str(text).lower())\n",
    "    text = re.sub('\\d', ' ', str(text).lower())\n",
    "    text = re.sub('https:\\S+', ' ', str(text).lower())\n",
    "    text = re.sub('[^a-z0-9 ]+', ' ', str(text).lower())\n",
    "    text = nltk.tokenize.word_tokenize(text, language='portuguese')\n",
    "    return ' '.join([w for w in text if not w in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f855b1",
   "metadata": {},
   "source": [
    "### Analise de score do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b388077",
   "metadata": {},
   "source": [
    "### Converter as frases em um dataset pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {'indices_id': ['0','1','2','3'],\n",
    "         'Frase original': ['Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?',\n",
    "                           'Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?',\n",
    "                           'Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?',\n",
    "                           'Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?'],\n",
    "         'Frases comparativas': ['De acordo com a escala de dor ali na parede', \n",
    "                                'qual valor você acha que mais representa a sua dor?',\n",
    "                                'De 0 a 10, qual o nível de intensidade da sua dor atualmente?',\n",
    "                                'Qual a intensidade da sua dor?'],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88957ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07967fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['frase_original_clean'] = dataset['Frase original'].apply(lambda x: anonymizer(x, stop_words))\n",
    "dataset['Frases_comparativas_clean'] = dataset['Frases comparativas'].apply(lambda x: anonymizer(x, stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b9f9c",
   "metadata": {},
   "source": [
    "### Comparative original column with column clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2353bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Frase original','frase_original_clean', 'Frases comparativas','Frases_comparativas_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1fd19",
   "metadata": {},
   "source": [
    "### Creating tokens and training model Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(data):\n",
    "    corpus = []\n",
    "    for sentence in data:\n",
    "        word_list = sentence.split(\" \")\n",
    "        corpus.append(word_list)\n",
    "    return corpus\n",
    "\n",
    "def createModel_word2vec(text,size=None,min_count=None,window=None):\n",
    "    model = gensim.models.word2vec.Word2Vec(text,min_count=min_count,window=window,workers=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Frases_comparativas_clean_wc\"] = build_corpus(dataset['Frases_comparativas_clean'])\n",
    "dataset[\"frase_original_clean_wc\"] = build_corpus(dataset['frase_original_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['frase_original_clean_wc',\"Frases_comparativas_clean_wc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07376ff",
   "metadata": {},
   "source": [
    "### Concat columns and convert all words in vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"concat\"] = dataset[\"frase_original_clean_wc\"] + dataset[\"Frases_comparativas_clean_wc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d391f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['concat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79123d",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8921939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wc = createModel_word2vec(dataset['concat'],min_count=1,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6839fcba",
   "metadata": {},
   "source": [
    "### Visualize Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a158d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wc.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in model_wc.wv.vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0b699",
   "metadata": {},
   "source": [
    "### Get similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(item[0],round(item[1],2)) for item in model_wc.most_similar('dor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [x for x in model_wc.wv.vocab]\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "for word in keys:\n",
    "    print(word)\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    for similar_word, _ in model_wc.most_similar(word, topn=30):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(model_wc[similar_word])\n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)\n",
    "    \n",
    "    model_wc.most_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591adebb",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=10, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254208fb",
   "metadata": {},
   "source": [
    "### Plot with similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, a, filename=None):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    tsne_plot_similar_words('Similar words from text', keys, embeddings_en_2d, word_clusters, 0.7,\n",
    "                        'similar_words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b05e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vocab = set(model_wc.wv.vocab)\n",
    "print(\"Loaded {} words in vocabulary\".format(len(w2v_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ca814",
   "metadata": {},
   "source": [
    "### Make a similarity matrix for words and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x for x in model_wc.wv.vocab]\n",
    "similarities = np.zeros((len(words), len(words)), dtype=np.float_)\n",
    "for idx1, word1 in enumerate(words):\n",
    "    for idx2, word2 in enumerate(words):\n",
    "        # note KeyError is possible if word doesn't exist\n",
    "        sim = model_wc.similarity(word1, word2)\n",
    "        similarities[idx1, idx2] = sim\n",
    "        \n",
    "df = pd.DataFrame.from_records(similarities, columns=words)\n",
    "df.index = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cbac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(1, 1, figsize=(14,8))\n",
    "cmap = plt.cm.Blues\n",
    "mask = np.zeros_like(df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(df, cmap=cmap, mask=mask, square=True, ax=ax)\n",
    "_=plt.yticks(rotation=90)\n",
    "plt.xlabel('Words')\n",
    "_=plt.xticks(rotation=45)\n",
    "_=plt.title(\"Similarities between words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e08b67",
   "metadata": {},
   "source": [
    "### Score a target sentence to source sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_sentence = \"You'd love to drink a cool refreshing Coke\"\n",
    "target_sentence = [\"Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?\",\n",
    "                  \"De acordo com a escala de dor ali na parede\",\n",
    "                  'qual valor você acha que mais representa a sua dor?',\n",
    "                                'De 0 a 10, qual o nível de intensidade da sua dor atualmente?',\n",
    "                                'Qual a intensidade da sua dor?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d60133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use n_similarity to compute a cosine similarity (should be reasonably robust)\n",
    "\n",
    "for i in target_sentence:\n",
    "    sentences = [x for x in model_wc.wv.vocab]\n",
    "    sentences_similarity = np.zeros(len(sentences))\n",
    "\n",
    "    target_sentence_words = [w for w in i.split() if w in w2v_vocab]\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        sentence_words = [w for w in sentence.split() if w in w2v_vocab]\n",
    "        sim = model_wc.n_similarity(target_sentence_words, sentence_words)\n",
    "        sentences_similarity[idx] = sim\n",
    "\n",
    "    result = list(zip(sentences_similarity, sentences))\n",
    "    result.sort(key=lambda item:item[0], reverse=True)\n",
    "    print(\"Target:\", target_sentence)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef9cc2",
   "metadata": {},
   "source": [
    "### Test some word relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wc.most_similar(positive=[\"acordo\", \"melhor\"], negative=['dor', 'intensidade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9f520",
   "metadata": {},
   "source": [
    "### Project a set of words (via their 30 dimensional vector) using T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b354eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "raw_words_of_interest = [x for x in model_wc.wv.vocab]\n",
    "\n",
    "words_of_interest = []\n",
    "for woi in raw_words_of_interest:\n",
    "    for word, _ in model_wc.most_similar(woi):\n",
    "        words_of_interest.append(word)\n",
    "\n",
    "words_of_interest = list(set(words_of_interest))\n",
    "\n",
    "vectors = []\n",
    "for word in set(words_of_interest):\n",
    "    vectors.append(model_wc[word])\n",
    "    \n",
    "vectors = np.vstack(vectors) # turn vectors into a 2D array <words x 300dim>\n",
    "\n",
    "model = TSNE(n_components=2, perplexity=10, random_state=0)\n",
    "X_tsne = model.fit_transform(vectors)\n",
    "df_after_tsne = pd.DataFrame.from_records(X_tsne, columns=['x', 'y'])\n",
    "df_after_tsne['labels'] = words_of_interest\n",
    "\n",
    "# calculate similarity from a target word to all words, to use as our colour\n",
    "target_word = \"dor\"\n",
    "similarities = []\n",
    "for woi in words_of_interest:\n",
    "    similarity = min(max(0, model_wc.similarity(target_word, woi)), 1.0)\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# plot the T-SNE layout for words, darker words means more similar to our target\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlim((min(X_tsne[:,0]), max(X_tsne[:,0])))\n",
    "plt.ylim((min(X_tsne[:,1]), max(X_tsne[:,1])))\n",
    "for idx in range(X_tsne.shape[0]):\n",
    "    x, y = X_tsne[idx]\n",
    "    label = words_of_interest[idx]\n",
    "    color=str(min(0.6, 1.0-similarities[idx])) # convert to string \"0.0\"..\"1.0\" as greyscale for mpl\n",
    "    plt.annotate(s=label, xy=(x, y), color=color)\n",
    "    #plt.annotate(s=label, xy=(x, y), weight=int(similarities[idx]*1000)) # use weight\n",
    "plt.tight_layout()\n",
    "plt.title(\"Word similarity (T-SNE) using vectors from {} words\\nColoured by similarity to '{}'\".format(len(words_of_interest), target_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e79ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
